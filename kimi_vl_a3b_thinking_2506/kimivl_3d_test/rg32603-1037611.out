created virtual environment CPython3.12.4.final.0-64 in 466ms
  creator CPython3Posix(dest=/localscratch/indrisch.1037611.0/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/home/indrisch/.local/share/virtualenv)
    added seed packages: pip==25.1.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v4, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: pip in /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages (25.1.1)
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v4, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /lustre09/project/6062393/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/flash_attn-2.8.1+cu12torch2.7cxx11abiFALSE-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 37))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiohappyeyeballs-2.6.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 1))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/aiohttp-3.12.13+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiosignal-1.4.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 3))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/airportsdata-20250706+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/annotated_types-0.7.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/anyio-3.7.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astor-0.8.1+computecanada-py2.py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 7))
Requirement already satisfied: asttokens==3.0.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 8)) (3.0.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/attrs-25.3.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/blake3-1.0.4+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 10))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/blobfile-3.0.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 11))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-6.1.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 12))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2025.8.3+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 13))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-3.4.3+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 14))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.2.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 15))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cloudpickle-3.1.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 16))
Requirement already satisfied: comm==0.2.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 17)) (0.2.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/compressed_tensors-0.10.2+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 18))
Requirement already satisfied: contourpy==1.3.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 19)) (1.3.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/cupy-13.3.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 20))
Requirement already satisfied: cycler==0.12.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 21)) (0.12.1+computecanada)
Requirement already satisfied: debugpy==1.8.12+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 22)) (1.8.12+computecanada)
Requirement already satisfied: decorator==5.1.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 23)) (5.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/depyf-0.18.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 24))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/dill-0.4.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 25))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/diskcache-5.6.3+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 26))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/distro-1.9.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 27))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/dnspython-2.7.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 28))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/einops-0.8.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 29))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/email_validator-2.2.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 30))
Requirement already satisfied: executing==2.2.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 31)) (2.2.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fastapi-0.116.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 32))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fastapi_cli-0.0.8+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 33))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fastapi_cloud_cli-0.1.5+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 34))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fastrlock-0.8.3+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 35))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.18.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 36))
Requirement already satisfied: fonttools==4.55.8+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 38)) (4.55.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/frozenlist-1.7.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 39))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2025.7.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 40))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gguf-0.17.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 41))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/h11-0.16.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 42))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/hf_xet-1.1.3+computecanada-cp37-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 43))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/httpcore-1.0.9+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 44))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/httptools-0.6.4+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 45))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/httpx-0.28.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 46))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/huggingface_hub-0.34.4+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 47))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.10+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 48))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/interegular-0.3.3+computecanada-py37-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 49))
Requirement already satisfied: ipykernel==6.29.5+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 50)) (6.29.5+computecanada)
Requirement already satisfied: ipython==8.32.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 51)) (8.32.0+computecanada)
Requirement already satisfied: ipywidgets==8.1.5+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 52)) (8.1.5+computecanada)
Requirement already satisfied: jedi==0.19.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 53)) (0.19.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jinja2-3.1.6+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 54))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/jiter-0.6.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 55))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jsonschema-4.25.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 56))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jsonschema_specifications-2025.4.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 57))
Requirement already satisfied: jupyter_client==8.6.3+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 58)) (8.6.3+computecanada)
Requirement already satisfied: jupyter_core==5.7.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 59)) (5.7.2+computecanada)
Requirement already satisfied: jupyterlab_widgets==3.0.13+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 60)) (3.0.13+computecanada)
Requirement already satisfied: kiwisolver==1.4.8+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 61)) (1.4.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/lark-1.2.2+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 62))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/llguidance-0.7.14+computecanada-cp39-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 63))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/llvmlite-0.44.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 64))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/lm_format_enforcer-0.10.12+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 65))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/lxml-5.3.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 66))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/markdown_it_py-3.0.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 67))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-3.0.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 68))
Requirement already satisfied: matplotlib==3.10.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 69)) (3.10.0+computecanada)
Requirement already satisfied: matplotlib_inline==0.1.7+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 70)) (0.1.7+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/mdurl-0.1.2+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 71))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/mistral_common-1.8.3+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 72))
Requirement already satisfied: mpmath==1.3.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 73)) (1.3.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/msgpack-1.1.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 74))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/msgspec-0.18.6+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 75))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/multidict-6.6.3+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 76))
Requirement already satisfied: nest_asyncio==1.6.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 77)) (1.6.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.5+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 78))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/ninja-1.11.1+computecanada-py2.py3-none-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 79))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/numba-0.61.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 80))
Requirement already satisfied: numpy==2.2.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 81)) (2.2.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/openai-1.90.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 82))
Requirement already satisfied: opencv_contrib_python==4.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcc12/opencv/4.11.0/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 83)) (4.11.0)
Requirement already satisfied: opencv_contrib_python_headless==4.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcc12/opencv/4.11.0/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 84)) (4.11.0)
Requirement already satisfied: opencv_python==4.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcc12/opencv/4.11.0/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 85)) (4.11.0)
Requirement already satisfied: opencv_python_headless==4.11.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcc12/opencv/4.11.0/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 86)) (4.11.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/outlines-0.1.11+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 87))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/outlines_core-0.1.26+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 88))
Requirement already satisfied: packaging==24.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 89)) (24.2+computecanada)
Requirement already satisfied: pandas==2.2.3+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 90)) (2.2.3+computecanada)
Requirement already satisfied: parso==0.8.4+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 91)) (0.8.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/partial_json_parser-0.2.1.1.post6+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 92))
Requirement already satisfied: pexpect==4.9.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 93)) (4.9.0+computecanada)
Requirement already satisfied: pillow==11.1.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 94)) (11.1.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/Pillow_SIMD-9.5.0.post2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 95))
Requirement already satisfied: platformdirs==4.3.6+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 96)) (4.3.6+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/prometheus_client-0.22.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 97))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/prometheus_fastapi_instrumentator-7.1.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 98))
Requirement already satisfied: prompt_toolkit==3.0.50+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 99)) (3.0.50+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/propcache-0.3.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 100))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/protobuf-6.31.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 101))
Requirement already satisfied: psutil==6.1.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 102)) (6.1.1+computecanada)
Requirement already satisfied: ptyprocess==0.7.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 103)) (0.7.0+computecanada)
Requirement already satisfied: pure_eval==0.2.3+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 104)) (0.2.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/py_cpuinfo-9.0.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 105))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pybase64-1.4.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 106))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pycountry-24.6.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 107))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pycryptodomex-3.19.0+computecanada-cp35-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 108))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pydantic-2.11.7+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 109))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/pydantic_core-2.33.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 110))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pydantic_extra_types-2.10.5+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 111))
Requirement already satisfied: pygments==2.19.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 112)) (2.19.1+computecanada)
Requirement already satisfied: pyparsing==3.2.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 113)) (3.2.1+computecanada)
Requirement already satisfied: python_dateutil==2.9.0.post0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 114)) (2.9.0.post0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_dotenv-1.1.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 115))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_json_logger-3.3.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 116))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_multipart-0.0.20+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 117))
Requirement already satisfied: pytz==2025.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 118)) (2025.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/PyYAML-6.0.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 119))
Requirement already satisfied: pyzmq==26.2.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 120)) (26.2.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/ray-2.43.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 121))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/referencing-0.36.2+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 122))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2024.11.6+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 123))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.32.4+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 124))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rich-14.1.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 125))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rich_toolkit-0.15.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 126))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/rignore-0.6.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 127))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/rpds_py-0.21.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 128))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/safetensors-0.5.3+computecanada-cp38-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 129))
Requirement already satisfied: scipy==1.15.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 130)) (1.15.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/sentencepiece-0.2.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 131))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-2.34.1+computecanada-py2.py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 132))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/setuptools-78.1.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 133))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shellingham-1.5.4+computecanada-py2.py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 134))
Requirement already satisfied: six==1.17.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 135)) (1.17.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sniffio-1.3.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 136))
Requirement already satisfied: stack_data==0.6.3+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 137)) (0.6.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/starlette-0.47.2+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 138))
Requirement already satisfied: sympy==1.13.3+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 139)) (1.13.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/tiktoken-0.9.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 140))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/tokenizers-0.21.1+computecanada-cp39-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 141))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.7.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 142))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torchaudio-2.7.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 143))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/torchvision-0.22.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 144))
Requirement already satisfied: tornado==6.4.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 145)) (6.4.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 146))
Requirement already satisfied: traitlets==5.14.3+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 147)) (5.14.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-4.53.2+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 148))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/triton-3.2.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 149))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typer-0.16.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 150))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.14.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 151))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_inspection-0.4.1+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 152))
Requirement already satisfied: tzdata==2025.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 153)) (2025.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-2.5.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 154))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/uvicorn-0.35.0+computecanada-py3-none-any.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 155))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/uvloop-0.20.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 156))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/vllm-0.9.2+computecanada-cp38-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 157))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/watchfiles-0.18.0+computecanada-cp37-abi3-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 158))
Requirement already satisfied: wcwidth==0.2.13+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 159)) (0.2.13+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/websockets-15.0.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 160))
Requirement already satisfied: widgetsnbextension==4.0.13+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.12/site-packages (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 161)) (4.0.13+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/xformers-0.0.30+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 162))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/xgrammar-0.1.19+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 163))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/yarl-1.20.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/hf_tutorial/vllm_requirements_2.txt (line 164))
Installing collected packages: triton, sentencepiece, py_cpuinfo, ninja, fastrlock, blake3, websockets, uvloop, urllib3, typing_extensions, tqdm, sniffio, shellingham, setuptools, safetensors, rpds_py, rignore, regex, PyYAML, python_multipart, python_json_logger, python_dotenv, pycryptodomex, pycountry, pybase64, protobuf, propcache, prometheus_client, Pillow_SIMD, partial_json_parser, networkx, multidict, msgspec, msgpack, mdurl, MarkupSafe, lxml, llvmlite, llguidance, lark, jiter, interegular, idna, httptools, hf_xet, h11, fsspec, frozenlist, filelock, einops, dnspython, distro, diskcache, dill, cupy, cloudpickle, click, charset_normalizer, certifi, cachetools, attrs, astor, annotated_types, airportsdata, aiohappyeyeballs, yarl, uvicorn, typing_inspection, sentry_sdk, requests, referencing, pydantic_core, numba, markdown_it_py, jinja2, httpcore, gguf, email_validator, depyf, blobfile, anyio, aiosignal, watchfiles, torch, tiktoken, starlette, rich, pydantic, jsonschema_specifications, huggingface_hub, httpx, aiohttp, xformers, typer, torchvision, torchaudio, tokenizers, rich_toolkit, pydantic_extra_types, prometheus_fastapi_instrumentator, openai, lm_format_enforcer, jsonschema, flash_attn, fastapi, transformers, ray, outlines_core, fastapi_cloud_cli, fastapi_cli, xgrammar, outlines, mistral_common, compressed_tensors, vllm

Successfully installed MarkupSafe-3.0.2+computecanada Pillow_SIMD-9.5.0.post2+computecanada PyYAML-6.0.2+computecanada aiohappyeyeballs-2.6.1+computecanada aiohttp-3.12.13+computecanada aiosignal-1.4.0+computecanada airportsdata-20250706+computecanada annotated_types-0.7.0+computecanada anyio-3.7.1+computecanada astor-0.8.1+computecanada attrs-25.3.0+computecanada blake3-1.0.4+computecanada blobfile-3.0.0+computecanada cachetools-6.1.0+computecanada certifi-2025.8.3+computecanada charset_normalizer-3.4.3+computecanada click-8.2.1+computecanada cloudpickle-3.1.1+computecanada compressed_tensors-0.10.2+computecanada cupy-13.3.0+computecanada depyf-0.18.0+computecanada dill-0.4.0+computecanada diskcache-5.6.3+computecanada distro-1.9.0+computecanada dnspython-2.7.0+computecanada einops-0.8.1+computecanada email_validator-2.2.0+computecanada fastapi-0.116.1+computecanada fastapi_cli-0.0.8+computecanada fastapi_cloud_cli-0.1.5+computecanada fastrlock-0.8.3+computecanada filelock-3.18.0+computecanada flash_attn-2.8.1 frozenlist-1.7.0+computecanada fsspec-2025.7.0+computecanada gguf-0.17.1+computecanada h11-0.16.0+computecanada hf_xet-1.1.3+computecanada httpcore-1.0.9+computecanada httptools-0.6.4+computecanada httpx-0.28.1+computecanada huggingface_hub-0.34.4+computecanada idna-3.10+computecanada interegular-0.3.3+computecanada jinja2-3.1.6+computecanada jiter-0.6.1+computecanada jsonschema-4.25.0+computecanada jsonschema_specifications-2025.4.1+computecanada lark-1.2.2+computecanada llguidance-0.7.14+computecanada llvmlite-0.44.0+computecanada lm_format_enforcer-0.10.12+computecanada lxml-5.3.1+computecanada markdown_it_py-3.0.0+computecanada mdurl-0.1.2+computecanada mistral_common-1.8.3+computecanada msgpack-1.1.0+computecanada msgspec-0.18.6+computecanada multidict-6.6.3+computecanada networkx-3.5+computecanada ninja-1.11.1+computecanada numba-0.61.2+computecanada openai-1.90.0+computecanada outlines-0.1.11+computecanada outlines_core-0.1.26+computecanada partial_json_parser-0.2.1.1.post6+computecanada prometheus_client-0.22.1+computecanada prometheus_fastapi_instrumentator-7.1.0+computecanada propcache-0.3.2+computecanada protobuf-6.31.1+computecanada py_cpuinfo-9.0.0+computecanada pybase64-1.4.1+computecanada pycountry-24.6.1+computecanada pycryptodomex-3.19.0+computecanada pydantic-2.11.7+computecanada pydantic_core-2.33.2+computecanada pydantic_extra_types-2.10.5+computecanada python_dotenv-1.1.1+computecanada python_json_logger-3.3.0+computecanada python_multipart-0.0.20+computecanada ray-2.43.0+computecanada referencing-0.36.2+computecanada regex-2024.11.6+computecanada requests-2.32.4+computecanada rich-14.1.0+computecanada rich_toolkit-0.15.0+computecanada rignore-0.6.2+computecanada rpds_py-0.21.0+computecanada safetensors-0.5.3+computecanada sentencepiece-0.2.0+computecanada sentry_sdk-2.34.1+computecanada setuptools-78.1.0+computecanada shellingham-1.5.4+computecanada sniffio-1.3.1+computecanada starlette-0.47.2+computecanada tiktoken-0.9.0+computecanada tokenizers-0.21.1+computecanada torch-2.7.0+computecanada torchaudio-2.7.0+computecanada torchvision-0.22.0+computecanada tqdm-4.67.1+computecanada transformers-4.53.2+computecanada triton-3.2.0+computecanada typer-0.16.0+computecanada typing_extensions-4.14.1+computecanada typing_inspection-0.4.1+computecanada urllib3-2.5.0+computecanada uvicorn-0.35.0+computecanada uvloop-0.20.0+computecanada vllm-0.9.2+computecanada watchfiles-0.18.0+computecanada websockets-15.0.1+computecanada xformers-0.0.30+computecanada xgrammar-0.1.19+computecanada yarl-1.20.1+computecanada
DEBUG 08-13 23:23:51 [__init__.py:31] No plugins for group vllm.platform_plugins found.
DEBUG 08-13 23:23:51 [__init__.py:35] Checking if TPU platform is available.
DEBUG 08-13 23:23:51 [__init__.py:45] TPU platform is not available because: No module named 'libtpu'
DEBUG 08-13 23:23:51 [__init__.py:52] Checking if CUDA platform is available.
DEBUG 08-13 23:23:51 [__init__.py:72] Confirmed CUDA platform is available.
DEBUG 08-13 23:23:51 [__init__.py:100] Checking if ROCm platform is available.
DEBUG 08-13 23:23:51 [__init__.py:114] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 08-13 23:23:51 [__init__.py:121] Checking if HPU platform is available.
DEBUG 08-13 23:23:51 [__init__.py:128] HPU platform is not available because habana_frameworks is not found.
DEBUG 08-13 23:23:51 [__init__.py:138] Checking if XPU platform is available.
DEBUG 08-13 23:23:51 [__init__.py:148] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 08-13 23:23:51 [__init__.py:155] Checking if CPU platform is available.
DEBUG 08-13 23:23:51 [__init__.py:177] Checking if Neuron platform is available.
DEBUG 08-13 23:23:51 [__init__.py:52] Checking if CUDA platform is available.
DEBUG 08-13 23:23:51 [__init__.py:72] Confirmed CUDA platform is available.
INFO 08-13 23:23:51 [__init__.py:244] Automatically detected platform cuda.
Namespace(question_file='/project/def-wangcs/indrisch/vllm/data/sqa-3d/ScanQA_format/SQA_scene0307_00_formatted_LLaVa3d.json', answer_file='/project/def-wangcs/indrisch/vllm/data/sqa-3d/ScanQA_format/SQA_scene0307_00_formatted_LLaVa3d_answers.json', image_folder='/project/def-wangcs/indrisch/vllm/data/ScanNet/scans', export_json='/project/def-wangcs/indrisch/vllm/kimi_vl_a3b_thinking_2506/kimivl_3d_test/experiments/SQA3D/scene0307_00/SQA_scene0307_00_formatted_LLaVa3d_pred-answers.json', model_path='moonshotai/Kimi-VL-A3B-Thinking-2506', device='cuda:0', sample_rate=800, num_chunks=1, chunk_idx=0, batch_size=4)
Step 1: Starting snapshot_download for model 'moonshotai/Kimi-VL-A3B-Thinking-2506' (local files only)...
Step 1 complete: Model available at: /home/indrisch/.cache/huggingface/hub/models--moonshotai--Kimi-VL-A3B-Thinking-2506/snapshots/04caee9653ccfdd3d081ac436167cfaddd8dd9df
Step 2: Initializing LLM...
DEBUG 08-13 23:23:53 [__init__.py:39] Available plugins for group vllm.general_plugins:
DEBUG 08-13 23:23:53 [__init__.py:41] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 08-13 23:23:53 [__init__.py:44] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 08-13 23:23:59 [config.py:841] This model supports multiple tasks: {'generate', 'reward', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 08-13 23:23:59 [config.py:1472] Using max model len 131072
DEBUG 08-13 23:23:59 [arg_utils.py:1692] Setting max_num_batched_tokens to 16384 for LLM_CLASS usage context.
INFO 08-13 23:23:59 [config.py:2285] Chunked prefill is enabled with max_num_batched_tokens=16384.
WARNING 08-13 23:24:00 [tokenizer.py:262] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.
DEBUG 08-13 23:24:04 [__init__.py:31] No plugins for group vllm.platform_plugins found.
DEBUG 08-13 23:24:04 [__init__.py:35] Checking if TPU platform is available.
DEBUG 08-13 23:24:04 [__init__.py:45] TPU platform is not available because: No module named 'libtpu'
DEBUG 08-13 23:24:04 [__init__.py:52] Checking if CUDA platform is available.
DEBUG 08-13 23:24:04 [__init__.py:72] Confirmed CUDA platform is available.
DEBUG 08-13 23:24:04 [__init__.py:100] Checking if ROCm platform is available.
DEBUG 08-13 23:24:04 [__init__.py:114] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 08-13 23:24:04 [__init__.py:121] Checking if HPU platform is available.
DEBUG 08-13 23:24:04 [__init__.py:128] HPU platform is not available because habana_frameworks is not found.
DEBUG 08-13 23:24:04 [__init__.py:138] Checking if XPU platform is available.
DEBUG 08-13 23:24:04 [__init__.py:148] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 08-13 23:24:04 [__init__.py:155] Checking if CPU platform is available.
DEBUG 08-13 23:24:04 [__init__.py:177] Checking if Neuron platform is available.
DEBUG 08-13 23:24:04 [__init__.py:52] Checking if CUDA platform is available.
DEBUG 08-13 23:24:04 [__init__.py:72] Confirmed CUDA platform is available.
INFO 08-13 23:24:04 [__init__.py:244] Automatically detected platform cuda.
INFO 08-13 23:24:06 [core.py:526] Waiting for init message from front-end.
DEBUG 08-13 23:24:06 [utils.py:545] HELLO from local core engine process 0.
DEBUG 08-13 23:24:06 [core.py:534] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/9198ce90-0915-4a48-95f6-f4ed4137f379'], outputs=['ipc:///tmp/67b3df5c-7ede-42d1-8319-e3fabdda5e84'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 0, 'data_parallel_size': 1})
DEBUG 08-13 23:24:06 [__init__.py:39] Available plugins for group vllm.general_plugins:
DEBUG 08-13 23:24:06 [__init__.py:41] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 08-13 23:24:06 [__init__.py:44] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 08-13 23:24:06 [core.py:69] Initializing a V1 LLM engine (v0.9.2) with config: model='/home/indrisch/.cache/huggingface/hub/models--moonshotai--Kimi-VL-A3B-Thinking-2506/snapshots/04caee9653ccfdd3d081ac436167cfaddd8dd9df', speculative_config=None, tokenizer='/home/indrisch/.cache/huggingface/hub/models--moonshotai--Kimi-VL-A3B-Thinking-2506/snapshots/04caee9653ccfdd3d081ac436167cfaddd8dd9df', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/indrisch/.cache/huggingface/hub/models--moonshotai--Kimi-VL-A3B-Thinking-2506/snapshots/04caee9653ccfdd3d081ac436167cfaddd8dd9df, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
DEBUG 08-13 23:24:06 [decorators.py:110] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
DEBUG 08-13 23:24:06 [decorators.py:110] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
DEBUG 08-13 23:24:06 [__init__.py:2802] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14fcd484f140>
DEBUG 08-13 23:24:06 [config.py:4834] enabled custom ops: Counter()
DEBUG 08-13 23:24:06 [config.py:4836] disabled custom ops: Counter()
DEBUG 08-13 23:24:07 [parallel_state.py:919] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.83.106.103:60207 backend=nccl
DEBUG 08-13 23:24:07 [parallel_state.py:970] Detected 1 nodes in the distributed environment
INFO 08-13 23:24:07 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
WARNING 08-13 23:24:07 [tokenizer.py:262] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.
DEBUG 08-13 23:24:07 [decorators.py:110] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
WARNING 08-13 23:24:10 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
DEBUG 08-13 23:24:10 [config.py:4834] enabled custom ops: Counter()
DEBUG 08-13 23:24:10 [config.py:4836] disabled custom ops: Counter()
INFO 08-13 23:24:10 [gpu_model_runner.py:1770] Starting to load model /home/indrisch/.cache/huggingface/hub/models--moonshotai--Kimi-VL-A3B-Thinking-2506/snapshots/04caee9653ccfdd3d081ac436167cfaddd8dd9df...
INFO 08-13 23:24:10 [gpu_model_runner.py:1775] Loading model from scratch...
INFO 08-13 23:24:10 [cuda.py:208] Using Triton MLA backend on V1 engine.
DEBUG 08-13 23:24:10 [backends.py:39] Using InductorAdaptor
DEBUG 08-13 23:24:10 [config.py:4834] enabled custom ops: Counter()
DEBUG 08-13 23:24:10 [config.py:4836] disabled custom ops: Counter({'rms_norm': 82, 'silu_and_mul': 27, 'unquantized_fused_moe': 26, 'rotary_embedding': 1})
Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:02<00:17,  2.95s/it]
Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:04<00:10,  2.09s/it]
DEBUG 08-13 23:24:16 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:06<00:08,  2.25s/it]
Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:09<00:06,  2.33s/it]
Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:11<00:04,  2.39s/it]
Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:14<00:02,  2.40s/it]
DEBUG 08-13 23:24:26 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:16<00:00,  2.42s/it]
Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:16<00:00,  2.39s/it]

INFO 08-13 23:24:27 [default_loader.py:272] Loading weights took 16.79 seconds
INFO 08-13 23:24:28 [gpu_model_runner.py:1801] Model loading took 30.6141 GiB and 17.165219 seconds
INFO 08-13 23:24:28 [gpu_model_runner.py:2238] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 12 image items of the maximum feature size.
DEBUG 08-13 23:24:29 [decorators.py:204] Start compiling function <code object forward at 0x1073ea20, file "/localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py", line 684>
DEBUG 08-13 23:24:36 [backends.py:461] Traced files (to be considered for compilation cache):
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/torch/_dynamo/polyfills/__init__.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/torch/nn/modules/container.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/torch/nn/modules/module.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/attention/layer.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/distributed/parallel_state.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/custom_op.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/activation.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/layer.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/layernorm.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/rotary_embedding.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/utils.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py
DEBUG 08-13 23:24:36 [backends.py:461] /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/platforms/interface.py
DEBUG 08-13 23:24:36 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
INFO 08-13 23:24:36 [backends.py:508] Using cache directory: /home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/backbone for vLLM's torch.compile
INFO 08-13 23:24:36 [backends.py:519] Dynamo bytecode transform time: 7.52 s
DEBUG 08-13 23:24:37 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:37 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
INFO 08-13 23:24:40 [backends.py:181] Cache the graph of shape None for later use
DEBUG 08-13 23:24:40 [backends.py:183] store the 0-th graph for shape None from inductor via handle ('fxsvtrewfidewrspo4yjkypgmucfda6wduagctaktx55mlnt3jms', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/fb/cfbdgw5wyhl7bxgkkgtihez3dqvmt2paktp4h3ocro2rfa6qznyf.py')
DEBUG 08-13 23:24:41 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:41 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:44 [backends.py:183] store the 1-th graph for shape None from inductor via handle ('f7dyeqjgbehwzlx3qs5cbggebosaahzixoyjy67edsm2sud2or4g', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/wt/cwtwmilyjtlfscrsmogogszqbwgnhgnrkkuugzvozw7u6bu3kqiv.py')
DEBUG 08-13 23:24:45 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:45 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.4 ms
DEBUG 08-13 23:24:46 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 08-13 23:24:47 [backends.py:183] store the 2-th graph for shape None from inductor via handle ('fniqq7uxvq4iewv76z4raxiuv7hllgagxgnytg2owankwjwfwbfz', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/4c/c4cqvbwiebmoruhpflyfb7hbsugx3rrvlaex43i4a3jhuhcpzhvw.py')
DEBUG 08-13 23:24:48 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:48 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:48 [backends.py:183] store the 3-th graph for shape None from inductor via handle ('fopgri32trndbcjitfn24m3uqchuv7jhqoe753bt2ybbyu7uatz4', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/ci/cci25fhsxheem56soph6qvei6rywtv6kuphbok5tsbm2t4j6bcht.py')
DEBUG 08-13 23:24:49 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:49 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:50 [backends.py:183] store the 4-th graph for shape None from inductor via handle ('fc2iibylvhxrfjgqba2k23g2ym7b27inyuj3jq64gf5xbv5uykwu', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/hv/chveulxqcdyolhots32smvrnombe2satvl4yavf7j73iasn674y2.py')
DEBUG 08-13 23:24:51 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:51 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:51 [backends.py:183] store the 5-th graph for shape None from inductor via handle ('fsrxeuex34b4k2nj5i7metuddickpfawb2q7u4kdrrnwmcgqd2u2', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/av/cavqg4zxtbcexwjdcezy4nnjc6uaz3lxbuig2kqrohzbgu6m6jfs.py')
DEBUG 08-13 23:24:52 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:52 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.3 ms
DEBUG 08-13 23:24:53 [backends.py:183] store the 6-th graph for shape None from inductor via handle ('few3ibas4xcp4tuvevlybm54txkisslyy6ukavnlv42k2ixxndjq', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/dh/cdhfv5bng4dkx3yyrl4g4vvicudozcdg5ovtauebe4rddcmzt5zg.py')
DEBUG 08-13 23:24:54 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:54 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:54 [backends.py:183] store the 7-th graph for shape None from inductor via handle ('fs7i2j3gpyf6253t54hgrav35h26swkipt663fxutvov4qzoc5ty', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/ka/ckagd63yb2hp7t2u3axdbtehi3wm3rswnyfzs32qyccwakhjjmrj.py')
DEBUG 08-13 23:24:55 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:55 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:56 [backends.py:183] store the 8-th graph for shape None from inductor via handle ('fonvbdtgoqwp44g6vaqyzm3smvlecuiyvu5x75bqvokvnmevoiqk', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/oz/coznhhvpvtqy7nj3vypny4sg6wgppeilccf7bgy44wcgvtlnqbrc.py')
DEBUG 08-13 23:24:56 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 08-13 23:24:57 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:57 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.8 ms
DEBUG 08-13 23:24:57 [backends.py:183] store the 9-th graph for shape None from inductor via handle ('fpvnxbpg4s3eofy7oyrgjapa6r2pxycx23q63cvjomjnfncepcrq', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/fr/cfrzrpzxdwnsochc3nr6g72iqawi2zshl2vw2vsjedv433c7kajv.py')
DEBUG 08-13 23:24:58 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:24:58 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:24:59 [backends.py:183] store the 10-th graph for shape None from inductor via handle ('fq44rxiuq55wgchb4r2mtbigmkgpzvlqkinejffja4q2jbvpvoa2', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/p2/cp2wfwkmzdloov6fjmzwaz7pff7p4i7f7oiiwqqci6lhoe2fykhe.py')
DEBUG 08-13 23:25:00 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:00 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:00 [backends.py:183] store the 11-th graph for shape None from inductor via handle ('f75gmqp4v27c2mpcufoe7f6ugdqijvgeymrdvsvby3qr4kfjl5aq', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/3l/c3lgvhv2lqemczh6lu6girygwicvm5jnysv3ui47mcyx62qebl6b.py')
DEBUG 08-13 23:25:01 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:01 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:02 [backends.py:183] store the 12-th graph for shape None from inductor via handle ('fxyjv35mxmtnpxdpm4ix4qcusqpi2cp4lzycux2vkoxsv5liv257', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/qp/cqpfpwgrlwhc35ptjqjbcfb6kb5qpis7kon4r6li7whm4cx6j3la.py')
DEBUG 08-13 23:25:03 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:03 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:03 [backends.py:183] store the 13-th graph for shape None from inductor via handle ('fv66gd362jvzht3djvgwbjffwohfzkspqdyweusi5h4g7zgmh4z6', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/vt/cvt37ymynzf7lqjduhulxp475mhn3roadafb6k6jfqn5ftnk2ctq.py')
DEBUG 08-13 23:25:04 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:04 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:04 [backends.py:183] store the 14-th graph for shape None from inductor via handle ('fizkjuwpi2kaiix24onto5nyhzgocruc3agk3pxyr3jlh54c2wkv', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/hc/chcpevuf7j2xwvuxpvtnvlrx2c6z7zt2vwwqzzw5khjtnpvzfoup.py')
DEBUG 08-13 23:25:05 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:05 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:06 [backends.py:183] store the 15-th graph for shape None from inductor via handle ('fztfnxx5hd44232okzuoifjn7gktvaih4ixs63plxktg7gqzno4k', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/2m/c2mtuzowtnpsdtbza7nqdzzg3equbdguwrfzbm3axkou4uhbukj3.py')
DEBUG 08-13 23:25:06 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 08-13 23:25:07 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:07 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.3 ms
DEBUG 08-13 23:25:07 [backends.py:183] store the 16-th graph for shape None from inductor via handle ('fh3kr7zp4ylvidqxc64paxx2ut5yx6cuoymfs6aj2cmmafqluqh2', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/il/cilrqt35lynylokktah3qmq5krxfrplcips33xcsyp2q2wdmgwpw.py')
DEBUG 08-13 23:25:09 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:09 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:09 [backends.py:183] store the 17-th graph for shape None from inductor via handle ('f5dz32p7bo67jxco634gpn3qarangoo32tpby6cd5pyvhslpxkxg', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/y5/cy5tcka54pi2c4clsna5f2va72xpfyuaecf2sbwdyy4ylg3tgmo2.py')
DEBUG 08-13 23:25:10 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:10 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:11 [backends.py:183] store the 18-th graph for shape None from inductor via handle ('ff45miydvskhxcxb62ktq367l7owurnexnyczrgp5cjykslx2puw', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/6f/c6f477v4m64l22p4twqrjwqct6rjzdmac4rufdgler57voxrg2ak.py')
DEBUG 08-13 23:25:12 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:12 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.3 ms
DEBUG 08-13 23:25:12 [backends.py:183] store the 19-th graph for shape None from inductor via handle ('fmvgx3b3wmf3jituy23faf3ffxpzbwe43mznmqjf7wryun2fphft', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/zi/czi2vm63oxmj4xw3mwjfgxpkiqnu3fiu5juux624obbk6blti3zf.py')
DEBUG 08-13 23:25:13 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:13 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:13 [backends.py:183] store the 20-th graph for shape None from inductor via handle ('fyhz7lwhdqrfmgygwmvtlhzvinw6er2t756vceygrwz2jqpsex3z', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/b2/cb2gtatsbjyt4gs4fev63jcwh43ip2dfptlpxampl5pbhj7rqatn.py')
DEBUG 08-13 23:25:14 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:14 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:15 [backends.py:183] store the 21-th graph for shape None from inductor via handle ('f4p74g5g7otbrdahjdxux6jlkzseg6ghd6gnew3j33dtorwgjsde', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/g4/cg4gckvzfmvkrmxau7penermxswrh3u5lmuxdpnmfidwgvastfue.py')
DEBUG 08-13 23:25:16 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:16 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:16 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 08-13 23:25:16 [backends.py:183] store the 22-th graph for shape None from inductor via handle ('fbwdedfworzvmqmzsn7grzt7nrh6vmwble5obs537o6ibuz765dm', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/wf/cwfi3hp5jsqsvfua4u66rx4vbmfbvhi3uzfbbjb337jn53gqvmdk.py')
DEBUG 08-13 23:25:17 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:17 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:18 [backends.py:183] store the 23-th graph for shape None from inductor via handle ('f6labqedmg3v6zsw4yi3pke5ve5reybb5jflxyde6iagrthvb4kz', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/2a/c2aq2zrzu7jn5y53hlfvrjl7hdgt4t3zoy5qh4qcblrfmerfjna2.py')
DEBUG 08-13 23:25:19 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:19 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:19 [backends.py:183] store the 24-th graph for shape None from inductor via handle ('fzzyfzf6carqpo7s4wcjyzcbpy7tqyn7tpoycddzrvxpu7d7b5yn', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/z7/cz7ye5bdmkvs2pxn6v4c3x4l44gnyhlxsuwogcyybyc6spjau5t3.py')
DEBUG 08-13 23:25:21 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:21 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:21 [backends.py:183] store the 25-th graph for shape None from inductor via handle ('fuewyrgaidpxspru73wpypzckir3aeofeoxfs25dblriiiabdueo', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/3x/c3xdmoj2jclkzdikga5xqpbozf4j7uw6huowvrajqyuldwjpgj7a.py')
DEBUG 08-13 23:25:22 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:22 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:23 [backends.py:183] store the 26-th graph for shape None from inductor via handle ('faiwvknkv5zezw3hcycv3zsqebumfdlei3zfcxworosyfgxwm2sz', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/sk/cskynfj4zwh5cpbsqiuepzlgtqsmaif5o2kp5ifmpqf5flifqsbg.py')
DEBUG 08-13 23:25:23 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
DEBUG 08-13 23:25:23 [vllm_inductor_pass.py:59] FixFunctionalizationPass completed in 0.2 ms
DEBUG 08-13 23:25:23 [backends.py:183] store the 27-th graph for shape None from inductor via handle ('fetfmouha6ldehbfmoeof4o75kanfcimrfq2fn33hycvqvhyhqhe', '/home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/inductor_cache/cb/ccbcnwarxzvhv5nuehvrbeshcaqjrzs6vfph7dxpwrurdl3uwzgc.py')
INFO 08-13 23:25:23 [backends.py:193] Compiling a graph for general shape takes 46.62 s
DEBUG 08-13 23:25:23 [backends.py:562] Computation graph saved to /home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/backbone/computation_graph.py
DEBUG 08-13 23:25:26 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 08-13 23:25:31 [wrapper.py:111] Dynamo transformed code saved to /home/indrisch/.cache/vllm/torch_compile_cache/a49fc872db/rank_0_0/backbone/transformed_code.py
WARNING 08-13 23:25:35 [fused_moe.py:690] Using default MoE config. Performance might be sub-optimal! Config file not found at /localscratch/indrisch.1037611.0/env/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/configs/E=64,N=1408,device_name=NVIDIA_H100_80GB_HBM3.json
DEBUG 08-13 23:25:36 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
INFO 08-13 23:25:40 [monitor.py:34] torch.compile takes 54.14 s in total
DEBUG 08-13 23:25:41 [gpu_worker.py:226] Initial free memory: 78.68 GiB, free memory: 47.63 GiB, requested GPU memory: 71.27 GiB
DEBUG 08-13 23:25:41 [gpu_worker.py:231] Memory profiling takes 73.39 seconds. Total non KV cache memory: 33.23GiB; torch peak memory increase: 2.45GiB; non-torch forward increase memory: 0.17GiB; weights memory: 30.61GiB.
INFO 08-13 23:25:41 [gpu_worker.py:232] Available KV cache memory: 38.04 GiB
INFO 08-13 23:25:42 [kv_cache_utils.py:716] GPU KV cache size: 1,313,168 tokens
INFO 08-13 23:25:42 [kv_cache_utils.py:720] Maximum concurrency for 131,072 tokens per request: 10.02x
DEBUG 08-13 23:25:42 [config.py:4834] enabled custom ops: Counter()
DEBUG 08-13 23:25:42 [config.py:4836] disabled custom ops: Counter({'rms_norm': 82, 'silu_and_mul': 27, 'unquantized_fused_moe': 26, 'rotary_embedding': 1})
Capturing CUDA graph shapes:   0%|          | 0/67 [00:00<?, ?it/s]DEBUG 08-13 23:25:42 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 512
DEBUG 08-13 23:25:42 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 512
Capturing CUDA graph shapes:   1%|         | 1/67 [00:00<00:37,  1.78it/s]DEBUG 08-13 23:25:42 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 504
DEBUG 08-13 23:25:42 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 504
Capturing CUDA graph shapes:   3%|         | 2/67 [00:01<00:36,  1.80it/s]DEBUG 08-13 23:25:43 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 496
DEBUG 08-13 23:25:43 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 496
Capturing CUDA graph shapes:   4%|         | 3/67 [00:01<00:35,  1.81it/s]DEBUG 08-13 23:25:43 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 488
DEBUG 08-13 23:25:44 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 488
Capturing CUDA graph shapes:   6%|         | 4/67 [00:02<00:34,  1.82it/s]DEBUG 08-13 23:25:44 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 480
DEBUG 08-13 23:25:44 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 480
Capturing CUDA graph shapes:   7%|         | 5/67 [00:02<00:34,  1.81it/s]DEBUG 08-13 23:25:45 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 472
DEBUG 08-13 23:25:45 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 472
Capturing CUDA graph shapes:   9%|         | 6/67 [00:03<00:33,  1.81it/s]DEBUG 08-13 23:25:45 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 464
DEBUG 08-13 23:25:45 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 464
Capturing CUDA graph shapes:  10%|         | 7/67 [00:03<00:33,  1.82it/s]DEBUG 08-13 23:25:46 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 456
DEBUG 08-13 23:25:46 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 456
DEBUG 08-13 23:25:46 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
Capturing CUDA graph shapes:  12%|        | 8/67 [00:04<00:32,  1.81it/s]DEBUG 08-13 23:25:46 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 448
DEBUG 08-13 23:25:46 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 448
Capturing CUDA graph shapes:  13%|        | 9/67 [00:04<00:31,  1.81it/s]DEBUG 08-13 23:25:47 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 440
DEBUG 08-13 23:25:47 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 440
Capturing CUDA graph shapes:  15%|        | 10/67 [00:05<00:31,  1.81it/s]DEBUG 08-13 23:25:47 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 432
DEBUG 08-13 23:25:47 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 432
Capturing CUDA graph shapes:  16%|        | 11/67 [00:06<00:31,  1.80it/s]DEBUG 08-13 23:25:48 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 424
DEBUG 08-13 23:25:48 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 424
Capturing CUDA graph shapes:  18%|        | 12/67 [00:06<00:30,  1.81it/s]DEBUG 08-13 23:25:48 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 416
DEBUG 08-13 23:25:48 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 416
Capturing CUDA graph shapes:  19%|        | 13/67 [00:07<00:29,  1.81it/s]DEBUG 08-13 23:25:49 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 408
DEBUG 08-13 23:25:49 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 408
Capturing CUDA graph shapes:  21%|        | 14/67 [00:07<00:29,  1.81it/s]DEBUG 08-13 23:25:50 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 400
DEBUG 08-13 23:25:50 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 400
Capturing CUDA graph shapes:  22%|       | 15/67 [00:08<00:28,  1.80it/s]DEBUG 08-13 23:25:50 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 392
DEBUG 08-13 23:25:50 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 392
Capturing CUDA graph shapes:  24%|       | 16/67 [00:08<00:28,  1.80it/s]DEBUG 08-13 23:25:51 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 384
DEBUG 08-13 23:25:51 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 384
Capturing CUDA graph shapes:  25%|       | 17/67 [00:09<00:28,  1.76it/s]DEBUG 08-13 23:25:51 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 376
DEBUG 08-13 23:25:51 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 376
Capturing CUDA graph shapes:  27%|       | 18/67 [00:09<00:27,  1.78it/s]DEBUG 08-13 23:25:52 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 368
DEBUG 08-13 23:25:52 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 368
Capturing CUDA graph shapes:  28%|       | 19/67 [00:10<00:26,  1.80it/s]DEBUG 08-13 23:25:52 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 360
DEBUG 08-13 23:25:52 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 360
Capturing CUDA graph shapes:  30%|       | 20/67 [00:11<00:26,  1.79it/s]DEBUG 08-13 23:25:53 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 352
DEBUG 08-13 23:25:53 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 352
Capturing CUDA graph shapes:  31%|      | 21/67 [00:11<00:25,  1.80it/s]DEBUG 08-13 23:25:53 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 344
DEBUG 08-13 23:25:53 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 344
Capturing CUDA graph shapes:  33%|      | 22/67 [00:12<00:24,  1.80it/s]DEBUG 08-13 23:25:54 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 336
DEBUG 08-13 23:25:54 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 336
Capturing CUDA graph shapes:  34%|      | 23/67 [00:12<00:24,  1.80it/s]DEBUG 08-13 23:25:55 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 328
DEBUG 08-13 23:25:55 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 328
Capturing CUDA graph shapes:  36%|      | 24/67 [00:13<00:23,  1.80it/s]DEBUG 08-13 23:25:55 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 320
DEBUG 08-13 23:25:55 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 320
Capturing CUDA graph shapes:  37%|      | 25/67 [00:13<00:23,  1.79it/s]DEBUG 08-13 23:25:56 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 312
DEBUG 08-13 23:25:56 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 312
DEBUG 08-13 23:25:56 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
Capturing CUDA graph shapes:  39%|      | 26/67 [00:14<00:22,  1.80it/s]DEBUG 08-13 23:25:56 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 304
DEBUG 08-13 23:25:56 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 304
Capturing CUDA graph shapes:  40%|      | 27/67 [00:14<00:22,  1.79it/s]DEBUG 08-13 23:25:57 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 296
DEBUG 08-13 23:25:57 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 296
Capturing CUDA graph shapes:  42%|     | 28/67 [00:15<00:21,  1.79it/s]DEBUG 08-13 23:25:57 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 288
DEBUG 08-13 23:25:57 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 288
Capturing CUDA graph shapes:  43%|     | 29/67 [00:16<00:21,  1.78it/s]DEBUG 08-13 23:25:58 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 280
DEBUG 08-13 23:25:58 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 280
Capturing CUDA graph shapes:  45%|     | 30/67 [00:16<00:20,  1.79it/s]DEBUG 08-13 23:25:58 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 272
DEBUG 08-13 23:25:59 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 272
Capturing CUDA graph shapes:  46%|     | 31/67 [00:17<00:20,  1.79it/s]DEBUG 08-13 23:25:59 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 264
DEBUG 08-13 23:25:59 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 264
Capturing CUDA graph shapes:  48%|     | 32/67 [00:17<00:19,  1.79it/s]DEBUG 08-13 23:26:00 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 256
DEBUG 08-13 23:26:00 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 256
Capturing CUDA graph shapes:  49%|     | 33/67 [00:18<00:19,  1.78it/s]DEBUG 08-13 23:26:00 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 248
DEBUG 08-13 23:26:00 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 248
Capturing CUDA graph shapes:  51%|     | 34/67 [00:18<00:18,  1.79it/s]DEBUG 08-13 23:26:01 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 240
DEBUG 08-13 23:26:01 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 240
Capturing CUDA graph shapes:  52%|    | 35/67 [00:19<00:17,  1.78it/s]DEBUG 08-13 23:26:01 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 232
DEBUG 08-13 23:26:01 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 232
Capturing CUDA graph shapes:  54%|    | 36/67 [00:20<00:17,  1.78it/s]DEBUG 08-13 23:26:02 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 224
DEBUG 08-13 23:26:02 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 224
Capturing CUDA graph shapes:  55%|    | 37/67 [00:20<00:16,  1.78it/s]DEBUG 08-13 23:26:02 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 216
DEBUG 08-13 23:26:02 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 216
Capturing CUDA graph shapes:  57%|    | 38/67 [00:21<00:16,  1.78it/s]DEBUG 08-13 23:26:03 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 208
DEBUG 08-13 23:26:03 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 208
Capturing CUDA graph shapes:  58%|    | 39/67 [00:21<00:15,  1.78it/s]DEBUG 08-13 23:26:04 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 200
DEBUG 08-13 23:26:04 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 200
Capturing CUDA graph shapes:  60%|    | 40/67 [00:22<00:15,  1.78it/s]DEBUG 08-13 23:26:04 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 192
DEBUG 08-13 23:26:04 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 192
Capturing CUDA graph shapes:  61%|    | 41/67 [00:22<00:14,  1.78it/s]DEBUG 08-13 23:26:05 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 184
DEBUG 08-13 23:26:05 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 184
Capturing CUDA graph shapes:  63%|   | 42/67 [00:23<00:14,  1.78it/s]DEBUG 08-13 23:26:05 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 176
DEBUG 08-13 23:26:05 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 176
Capturing CUDA graph shapes:  64%|   | 43/67 [00:23<00:13,  1.78it/s]DEBUG 08-13 23:26:06 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 168
DEBUG 08-13 23:26:06 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 168
DEBUG 08-13 23:26:06 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
Capturing CUDA graph shapes:  66%|   | 44/67 [00:24<00:12,  1.78it/s]DEBUG 08-13 23:26:06 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 160
DEBUG 08-13 23:26:06 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 160
Capturing CUDA graph shapes:  67%|   | 45/67 [00:25<00:12,  1.77it/s]DEBUG 08-13 23:26:07 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 152
DEBUG 08-13 23:26:07 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 152
Capturing CUDA graph shapes:  69%|   | 46/67 [00:25<00:11,  1.78it/s]DEBUG 08-13 23:26:07 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 144
DEBUG 08-13 23:26:08 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 144
Capturing CUDA graph shapes:  70%|   | 47/67 [00:26<00:11,  1.77it/s]DEBUG 08-13 23:26:08 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 136
DEBUG 08-13 23:26:08 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 136
Capturing CUDA graph shapes:  72%|  | 48/67 [00:26<00:10,  1.78it/s]DEBUG 08-13 23:26:09 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 128
DEBUG 08-13 23:26:09 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 128
Capturing CUDA graph shapes:  73%|  | 49/67 [00:27<00:10,  1.77it/s]DEBUG 08-13 23:26:09 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 120
DEBUG 08-13 23:26:09 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 120
Capturing CUDA graph shapes:  75%|  | 50/67 [00:27<00:09,  1.77it/s]DEBUG 08-13 23:26:10 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 112
DEBUG 08-13 23:26:10 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 112
Capturing CUDA graph shapes:  76%|  | 51/67 [00:28<00:09,  1.77it/s]DEBUG 08-13 23:26:10 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 104
DEBUG 08-13 23:26:10 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 104
Capturing CUDA graph shapes:  78%|  | 52/67 [00:29<00:08,  1.77it/s]DEBUG 08-13 23:26:11 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 96
DEBUG 08-13 23:26:11 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 96
Capturing CUDA graph shapes:  79%|  | 53/67 [00:29<00:07,  1.77it/s]DEBUG 08-13 23:26:11 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 88
DEBUG 08-13 23:26:11 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 88
Capturing CUDA graph shapes:  81%|  | 54/67 [00:30<00:07,  1.77it/s]DEBUG 08-13 23:26:12 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 80
DEBUG 08-13 23:26:12 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 80
Capturing CUDA graph shapes:  82%| | 55/67 [00:30<00:06,  1.77it/s]DEBUG 08-13 23:26:13 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 72
DEBUG 08-13 23:26:13 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 72
Capturing CUDA graph shapes:  84%| | 56/67 [00:31<00:06,  1.77it/s]DEBUG 08-13 23:26:13 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 64
DEBUG 08-13 23:26:14 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 64
Capturing CUDA graph shapes:  85%| | 57/67 [00:32<00:07,  1.41it/s]DEBUG 08-13 23:26:14 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 56
DEBUG 08-13 23:26:14 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 56
Capturing CUDA graph shapes:  87%| | 58/67 [00:32<00:06,  1.49it/s]DEBUG 08-13 23:26:15 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 48
DEBUG 08-13 23:26:15 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 48
Capturing CUDA graph shapes:  88%| | 59/67 [00:33<00:05,  1.56it/s]DEBUG 08-13 23:26:15 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 40
DEBUG 08-13 23:26:15 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 40
Capturing CUDA graph shapes:  90%| | 60/67 [00:34<00:04,  1.62it/s]DEBUG 08-13 23:26:16 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 32
DEBUG 08-13 23:26:16 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 32
DEBUG 08-13 23:26:16 [utils.py:475] Waiting for 1 local, 0 remote core engine proc(s) to start.
Capturing CUDA graph shapes:  91%| | 61/67 [00:34<00:03,  1.66it/s]DEBUG 08-13 23:26:16 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 24
DEBUG 08-13 23:26:16 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 24
Capturing CUDA graph shapes:  93%|| 62/67 [00:35<00:02,  1.70it/s]DEBUG 08-13 23:26:17 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 16
DEBUG 08-13 23:26:17 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 16
Capturing CUDA graph shapes:  94%|| 63/67 [00:35<00:02,  1.71it/s]DEBUG 08-13 23:26:18 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 8
DEBUG 08-13 23:26:18 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 8
Capturing CUDA graph shapes:  96%|| 64/67 [00:36<00:01,  1.74it/s]DEBUG 08-13 23:26:18 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 4
DEBUG 08-13 23:26:19 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 4
Capturing CUDA graph shapes:  97%|| 65/67 [00:37<00:01,  1.40it/s]DEBUG 08-13 23:26:19 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 2
DEBUG 08-13 23:26:19 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 2
Capturing CUDA graph shapes:  99%|| 66/67 [00:38<00:00,  1.35it/s]DEBUG 08-13 23:26:20 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 1
DEBUG 08-13 23:26:21 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 1
Capturing CUDA graph shapes: 100%|| 67/67 [00:39<00:00,  1.04s/it]Capturing CUDA graph shapes: 100%|| 67/67 [00:39<00:00,  1.68it/s]
INFO 08-13 23:26:22 [gpu_model_runner.py:2326] Graph capturing finished in 40 secs, took 0.93 GiB
INFO 08-13 23:26:22 [core.py:172] init engine (profile, create kv cache, warmup model) took 114.00 seconds
WARNING 08-13 23:26:22 [tokenizer.py:262] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.
DEBUG 08-13 23:26:22 [utils.py:545] READY from local core engine process 0.
DEBUG 08-13 23:26:22 [core.py:614] EngineCore waiting for work.
DEBUG 08-13 23:26:22 [core.py:614] EngineCore waiting for work.
Step 2 complete: LLM initialized in 149.27s
Step 3: Loading processor...
Step 3 complete: Processor loaded.
Step 4: Creating sampling params...
Step 4 complete: Sampling params ready.
========== Processing question: 220602000376 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D74C7260>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5DBAE7890>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C3430EF0>}, {'type': 'text', 'text': 'What color is the cloth on my left?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:26:24 [decorators.py:110] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
Adding requests: 100%|| 1/1 [00:02<00:00,  2.68s/it]Adding requests: 100%|| 1/1 [00:02<00:00,  2.68s/it]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]DEBUG 08-13 23:26:26 [core.py:620] EngineCore loop active.
Processed prompts: 100%|| 1/1 [00:04<00:00,  4.16s/it, est. speed input: 1217.60 toks/s, output: 40.35 toks/s]Processed prompts: 100%|| 1/1 [00:04<00:00,  4.16s/it, est. speed input: 1217.60 toks/s, output: 40.35 toks/s]Processed prompts: 100%|| 1/1 [00:04<00:00,  4.16s/it, est. speed input: 1217.60 toks/s, output: 40.35 toks/s]
DEBUG 08-13 23:26:31 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602000923 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FD7C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A8CF5BB830>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5DBAE78F0>}, {'type': 'text', 'text': 'How should I move to leave this room through the door near most?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:26:31 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 27.97it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:11<00:00, 11.02s/it, est. speed input: 460.41 toks/s, output: 61.07 toks/s]Processed prompts: 100%|| 1/1 [00:11<00:00, 11.02s/it, est. speed input: 460.41 toks/s, output: 61.07 toks/s]Processed prompts: 100%|| 1/1 [00:11<00:00, 11.02s/it, est. speed input: 460.41 toks/s, output: 61.07 toks/s]
DEBUG 08-13 23:26:42 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602000961 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C31482F0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C314B2F0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34923F0>}, {'type': 'text', 'text': "What is beside the door that is on my 7 o'clock?"}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:26:43 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 25.87it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:05<00:00,  5.27s/it, est. speed input: 962.67 toks/s, output: 95.43 toks/s]Processed prompts: 100%|| 1/1 [00:05<00:00,  5.27s/it, est. speed input: 962.67 toks/s, output: 95.43 toks/s]Processed prompts: 100%|| 1/1 [00:05<00:00,  5.27s/it, est. speed input: 962.67 toks/s, output: 95.43 toks/s]
DEBUG 08-13 23:26:48 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602001087 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34C9280>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D763D430>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C318BC80>}, {'type': 'text', 'text': 'What object is to my right?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:26:49 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 26.20it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.62s/it, est. speed input: 1398.69 toks/s, output: 94.96 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.62s/it, est. speed input: 1398.69 toks/s, output: 94.96 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.62s/it, est. speed input: 1398.69 toks/s, output: 94.96 toks/s]
DEBUG 08-13 23:26:52 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602001196 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FD7C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A8CF5BB830>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9746C30>}, {'type': 'text', 'text': 'To ensure my clothes come out smelling nice on the washing machine in front of me, what should I add to the washing machine?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:26:53 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 27.36it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.26s/it, est. speed input: 4035.84 toks/s, output: 96.01 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.26s/it, est. speed input: 4035.84 toks/s, output: 96.01 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.26s/it, est. speed input: 4035.84 toks/s, output: 96.01 toks/s]
DEBUG 08-13 23:26:54 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602001387 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34CA0C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9810D40>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C314B4A0>}, {'type': 'text', 'text': 'Need to take clothes out after they done washing, which dicrection to go?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:26:55 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.74it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:14<00:00, 14.50s/it, est. speed input: 349.99 toks/s, output: 93.08 toks/s]Processed prompts: 100%|| 1/1 [00:14<00:00, 14.50s/it, est. speed input: 349.99 toks/s, output: 93.08 toks/s]Processed prompts: 100%|| 1/1 [00:14<00:00, 14.50s/it, est. speed input: 349.99 toks/s, output: 93.08 toks/s]
DEBUG 08-13 23:27:09 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602001473 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C3188D70>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D71D6B70>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A8CF5BB830>}, {'type': 'text', 'text': 'Is it possible to exit the room by walking towards my left?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:10 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.55it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.29s/it, est. speed input: 3945.97 toks/s, output: 96.45 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.29s/it, est. speed input: 3945.97 toks/s, output: 96.45 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.29s/it, est. speed input: 3945.97 toks/s, output: 96.45 toks/s]
DEBUG 08-13 23:27:11 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602001750 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9810D40>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34CA0C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C314B2F0>}, {'type': 'text', 'text': 'Does the table in front and the washing machine behind have similar color?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:12 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 22.51it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:05<00:00,  5.65s/it, est. speed input: 897.50 toks/s, output: 95.52 toks/s]Processed prompts: 100%|| 1/1 [00:05<00:00,  5.65s/it, est. speed input: 897.50 toks/s, output: 95.52 toks/s]Processed prompts: 100%|| 1/1 [00:05<00:00,  5.65s/it, est. speed input: 897.50 toks/s, output: 95.52 toks/s]
DEBUG 08-13 23:27:17 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602002648 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D3501190>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FD340>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FD7C0>}, {'type': 'text', 'text': 'How should I turn to leave the room through the door near the washing machine?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:18 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.30it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.09s/it, est. speed input: 1641.48 toks/s, output: 95.40 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.09s/it, est. speed input: 1641.48 toks/s, output: 95.40 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.09s/it, est. speed input: 1641.48 toks/s, output: 95.40 toks/s]
DEBUG 08-13 23:27:21 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602003449 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9746C30>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D76AFF20>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C31482F0>}, {'type': 'text', 'text': 'Where do I wash my hands?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:22 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 21.49it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 6063.79 toks/s, output: 96.93 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 6063.79 toks/s, output: 96.93 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 6063.79 toks/s, output: 96.93 toks/s]
DEBUG 08-13 23:27:22 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602005148 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D71D6B70>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34C9280>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FCA40>}, {'type': 'text', 'text': 'What is the pile of clothes behind me lying on?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:23 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 21.48it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:04<00:00,  4.03s/it, est. speed input: 1258.81 toks/s, output: 95.82 toks/s]Processed prompts: 100%|| 1/1 [00:04<00:00,  4.03s/it, est. speed input: 1258.81 toks/s, output: 95.82 toks/s]Processed prompts: 100%|| 1/1 [00:04<00:00,  4.03s/it, est. speed input: 1258.81 toks/s, output: 95.82 toks/s]
DEBUG 08-13 23:27:27 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602005593 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34923F0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D35013D0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D35012E0>}, {'type': 'text', 'text': 'What is behind the table in front of me?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:28 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.39it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:07<00:00,  7.27s/it, est. speed input: 697.12 toks/s, output: 95.01 toks/s]Processed prompts: 100%|| 1/1 [00:07<00:00,  7.27s/it, est. speed input: 697.12 toks/s, output: 95.01 toks/s]Processed prompts: 100%|| 1/1 [00:07<00:00,  7.27s/it, est. speed input: 697.12 toks/s, output: 95.01 toks/s]
DEBUG 08-13 23:27:35 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602005636 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FD340>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34FD7C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34CA0C0>}, {'type': 'text', 'text': 'Can I see the windows from my angle of view?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:36 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 25.81it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 6432.28 toks/s, output: 96.40 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 6432.28 toks/s, output: 96.40 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 6432.28 toks/s, output: 96.40 toks/s]
DEBUG 08-13 23:27:36 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602005990 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D35013D0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C31482F0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C314A750>}, {'type': 'text', 'text': 'What color is the shower on my left?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:37 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.63it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.27s/it, est. speed input: 4000.00 toks/s, output: 96.27 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.27s/it, est. speed input: 4000.00 toks/s, output: 96.27 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.27s/it, est. speed input: 4000.00 toks/s, output: 96.27 toks/s]
DEBUG 08-13 23:27:38 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602006659 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D763D430>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A8CF5BB830>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34CA0C0>}, {'type': 'text', 'text': 'To what direction should I move to wash my hands in the sink?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:39 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 25.99it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 6734.64 toks/s, output: 96.89 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 6734.64 toks/s, output: 96.89 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 6734.64 toks/s, output: 96.89 toks/s]
DEBUG 08-13 23:27:40 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602006706 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9810B00>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9746C30>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D76AFF20>}, {'type': 'text', 'text': 'Which side of the room is the washing machine on?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:40 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 22.07it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 5404.75 toks/s, output: 96.99 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 5404.75 toks/s, output: 96.99 toks/s]Processed prompts: 100%|| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 5404.75 toks/s, output: 96.99 toks/s]
DEBUG 08-13 23:27:41 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602006742 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D3501190>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5DBAE7890>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34923F0>}, {'type': 'text', 'text': 'What is on top of the cabinet that is on my right?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:42 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.42it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 3068.41 toks/s, output: 96.17 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 3068.41 toks/s, output: 96.17 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 3068.41 toks/s, output: 96.17 toks/s]
DEBUG 08-13 23:27:43 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602006975 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34497C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D9747500>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D35013D0>}, {'type': 'text', 'text': 'What keeps the water warm on the shower to my left that is behind me?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:44 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.04it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.56s/it, est. speed input: 3261.99 toks/s, output: 96.39 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.56s/it, est. speed input: 3261.99 toks/s, output: 96.39 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.56s/it, est. speed input: 3261.99 toks/s, output: 96.39 toks/s]
DEBUG 08-13 23:27:45 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602007312 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C314B2F0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C311E930>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C34923F0>}, {'type': 'text', 'text': 'What is nearer to me, the washing machine or this cabinet?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:46 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 23.52it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.44s/it, est. speed input: 1473.07 toks/s, output: 96.11 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.44s/it, est. speed input: 1473.07 toks/s, output: 96.11 toks/s]Processed prompts: 100%|| 1/1 [00:03<00:00,  3.44s/it, est. speed input: 1473.07 toks/s, output: 96.11 toks/s]
DEBUG 08-13 23:27:50 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602007500 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D763D430>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D76AFF20>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5C318BC80>}, {'type': 'text', 'text': 'What is on the door that is see through on my left side?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:50 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 23.83it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.43s/it, est. speed input: 3550.76 toks/s, output: 95.17 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.43s/it, est. speed input: 3550.76 toks/s, output: 95.17 toks/s]Processed prompts: 100%|| 1/1 [00:01<00:00,  1.43s/it, est. speed input: 3550.76 toks/s, output: 95.17 toks/s]
DEBUG 08-13 23:27:52 [core.py:614] EngineCore waiting for work.
Processed batch 1/1
Total     : 85.03 GB
Reserved  : 0.00 GB
Allocated : 0.00 GB
Free      : 85.03 GB
========== Processing question: 220602008273 ==========
Images being used for this question: 3
[{'role': 'assistant', 'content': [{'type': 'text', 'text': "I am a helpful assistant. For a given question, I will concisely provide my reasoning traces. I will provide my final answer after '**Answer:**'. If the images don't provide enough information, my final answer will be 'IDK'. Because I am processing the images in batches, along with the question I will also see my reasoning of the most recent batch, which I will use to help me answer."}, {'type': 'text', 'text': 'I am currently looking at the first batch of images.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D71442C0>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D74C4E30>}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1296x968 at 0x14A5D3501190>}, {'type': 'text', 'text': 'How many shelves are on my right side?'}]}]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]DEBUG 08-13 23:27:52 [core.py:620] EngineCore loop active.
Adding requests: 100%|| 1/1 [00:00<00:00, 24.80it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]slurmstepd: error: *** JOB 1037611 ON rg32603 CANCELLED AT 2025-08-14T03:28:02 DUE TO TIME LIMIT ***
